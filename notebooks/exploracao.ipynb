{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados\n",
    "## Hackathon Participa DF - Categoria Acesso à Informação\n",
    "\n",
    "Este notebook contém a análise exploratória dos dados de pedidos de acesso à informação.\n",
    "\n",
    "**Objetivo**: Identificar pedidos que contenham dados pessoais (nome, CPF, RG, telefone, e-mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Adicionar src ao path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from preprocessamento import carregar_dados, preprocessar_dados\n",
    "from modelo import DetectorPadroesRegex, DetectorNER\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"Ambiente configurado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados de treino\n",
    "# NOTA: Ajuste o caminho conforme os dados fornecidos pela CGDF\n",
    "caminho_dados = '../dados/treino/pedidos_treino.csv'\n",
    "\n",
    "# Verificar se o arquivo existe\n",
    "if Path(caminho_dados).exists():\n",
    "    df = carregar_dados(caminho_dados)\n",
    "    print(f\"Dados carregados com sucesso!\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "else:\n",
    "    print(f\"AVISO: Arquivo não encontrado: {caminho_dados}\")\n",
    "    print(\"Criando dados de exemplo para demonstração...\")\n",
    "    \n",
    "    # Dados de exemplo\n",
    "    df = pd.DataFrame({\n",
    "        'id_pedido': range(1, 11),\n",
    "        'texto_pedido': [\n",
    "            \"Gostaria de informações sobre o orçamento de 2025\",\n",
    "            \"Meu CPF é 123.456.789-00 e preciso de informações sobre meu processo\",\n",
    "            \"Solicito dados sobre obras públicas no DF\",\n",
    "            \"Entre em contato pelo email joao.silva@email.com\",\n",
    "            \"Qual o status do processo administrativo?\",\n",
    "            \"Meu telefone é (61) 98765-4321 para retorno\",\n",
    "            \"Pedro Santos da Silva solicita informações\",\n",
    "            \"Relatório de gastos públicos em 2024\",\n",
    "            \"RG 1.234.567 SSP/DF necessário para análise\",\n",
    "            \"Informações sobre licitações abertas\"\n",
    "        ],\n",
    "        'contem_dados_pessoais': [False, True, False, True, False, True, True, False, True, False]\n",
    "    })\n",
    "    print(\"Dados de exemplo criados.\")\n",
    "\n",
    "# Mostrar primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visão Geral dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações básicas\n",
    "print(\"Informações do Dataset:\")\n",
    "print(f\"Total de pedidos: {len(df)}\")\n",
    "print(f\"Colunas: {df.columns.tolist()}\")\n",
    "print(f\"\\nTipos de dados:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nValores nulos:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição da variável alvo\n",
    "if 'contem_dados_pessoais' in df.columns:\n",
    "    print(\"Distribuição de Classes:\")\n",
    "    print(df['contem_dados_pessoais'].value_counts())\n",
    "    print(f\"\\nProporção:\")\n",
    "    print(df['contem_dados_pessoais'].value_counts(normalize=True))\n",
    "    \n",
    "    # Plotar\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Contagem\n",
    "    df['contem_dados_pessoais'].value_counts().plot(kind='bar', ax=axes[0], color=['steelblue', 'coral'])\n",
    "    axes[0].set_title('Distribuição de Classes', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Contém Dados Pessoais')\n",
    "    axes[0].set_ylabel('Quantidade')\n",
    "    axes[0].set_xticklabels(['Não', 'Sim'], rotation=0)\n",
    "    \n",
    "    # Proporção\n",
    "    df['contem_dados_pessoais'].value_counts(normalize=True).plot(kind='pie', ax=axes[1], autopct='%1.1f%%')\n",
    "    axes[1].set_title('Proporção de Classes', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Coluna 'contem_dados_pessoais' não encontrada (dados de teste).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise dos Textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas dos textos\n",
    "df['tamanho_texto'] = df['texto_pedido'].apply(len)\n",
    "df['qtd_palavras'] = df['texto_pedido'].apply(lambda x: len(str(x).split()))\n",
    "df['qtd_numeros'] = df['texto_pedido'].apply(lambda x: len(re.findall(r'\\d', str(x))))\n",
    "\n",
    "print(\"Estatísticas dos Textos:\")\n",
    "print(df[['tamanho_texto', 'qtd_palavras', 'qtd_numeros']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição do tamanho dos textos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Tamanho do texto\n",
    "axes[0, 0].hist(df['tamanho_texto'], bins=30, color='skyblue', edgecolor='black')\n",
    "axes[0, 0].set_title('Distribuição do Tamanho dos Textos (caracteres)', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Tamanho')\n",
    "axes[0, 0].set_ylabel('Frequência')\n",
    "\n",
    "# Quantidade de palavras\n",
    "axes[0, 1].hist(df['qtd_palavras'], bins=30, color='lightcoral', edgecolor='black')\n",
    "axes[0, 1].set_title('Distribuição da Quantidade de Palavras', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Quantidade de Palavras')\n",
    "axes[0, 1].set_ylabel('Frequência')\n",
    "\n",
    "# Quantidade de números\n",
    "axes[1, 0].hist(df['qtd_numeros'], bins=30, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Distribuição da Quantidade de Números', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Quantidade de Números')\n",
    "axes[1, 0].set_ylabel('Frequência')\n",
    "\n",
    "# Boxplot por classe (se disponível)\n",
    "if 'contem_dados_pessoais' in df.columns:\n",
    "    df.boxplot(column='qtd_numeros', by='contem_dados_pessoais', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Quantidade de Números por Classe', fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Contém Dados Pessoais')\n",
    "    axes[1, 1].set_ylabel('Quantidade de Números')\n",
    "    plt.suptitle('')\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'Rótulos não disponíveis', ha='center', va='center')\n",
    "    axes[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Detecção de Padrões com Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar detector de padrões\n",
    "detector_regex = DetectorPadroesRegex()\n",
    "\n",
    "# Detectar padrões em todos os textos\n",
    "print(\"Detectando padrões com regex...\")\n",
    "deteccoes = df['texto_pedido'].apply(detector_regex.detectar_todos)\n",
    "\n",
    "# Expandir dicionários em colunas\n",
    "df_deteccoes = pd.DataFrame(deteccoes.tolist())\n",
    "df_combined = pd.concat([df, df_deteccoes], axis=1)\n",
    "\n",
    "# Estatísticas de detecção\n",
    "print(\"\\nPadrões Detectados:\")\n",
    "print(f\"CPF: {df_deteccoes['cpf'].sum()} pedidos\")\n",
    "print(f\"RG: {df_deteccoes['rg'].sum()} pedidos\")\n",
    "print(f\"Telefone: {df_deteccoes['telefone'].sum()} pedidos\")\n",
    "print(f\"E-mail: {df_deteccoes['email'].sum()} pedidos\")\n",
    "print(f\"\\nQualquer padrão: {df_deteccoes.any(axis=1).sum()} pedidos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar detecções\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "tipos_dados = ['cpf', 'rg', 'telefone', 'email']\n",
    "contagens = [df_deteccoes[tipo].sum() for tipo in tipos_dados]\n",
    "\n",
    "bars = ax.bar(tipos_dados, contagens, color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'])\n",
    "ax.set_title('Quantidade de Detecções por Tipo de Dado Pessoal', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Tipo de Dado')\n",
    "ax.set_ylabel('Quantidade de Pedidos')\n",
    "\n",
    "# Adicionar valores nas barras\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exemplos de Pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos com dados pessoais detectados por regex\n",
    "if df_deteccoes.any(axis=1).sum() > 0:\n",
    "    print(\"Exemplos de pedidos COM dados pessoais (detectados por regex):\\n\")\n",
    "    exemplos_com = df_combined[df_deteccoes.any(axis=1)].head(5)\n",
    "    \n",
    "    for idx, row in exemplos_com.iterrows():\n",
    "        print(f\"ID: {row['id_pedido']}\")\n",
    "        print(f\"Texto: {row['texto_pedido'][:200]}...\")\n",
    "        detectados = [tipo for tipo in tipos_dados if row[tipo]]\n",
    "        print(f\"Detectados: {', '.join(detectados)}\")\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"Nenhum padrão detectado nos dados de exemplo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos sem dados pessoais\n",
    "if (~df_deteccoes.any(axis=1)).sum() > 0:\n",
    "    print(\"\\nExemplos de pedidos SEM dados pessoais (não detectados por regex):\\n\")\n",
    "    exemplos_sem = df_combined[~df_deteccoes.any(axis=1)].head(5)\n",
    "    \n",
    "    for idx, row in exemplos_sem.iterrows():\n",
    "        print(f\"ID: {row['id_pedido']}\")\n",
    "        print(f\"Texto: {row['texto_pedido'][:200]}...\")\n",
    "        print(\"-\" * 80)\n",
    "else:\n",
    "    print(\"Todos os pedidos contêm algum padrão detectado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análise de Performance (se rótulos disponíveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'contem_dados_pessoais' in df.columns:\n",
    "    # Comparar detecções com rótulos verdadeiros\n",
    "    df_combined['detectado_regex'] = df_deteccoes.any(axis=1)\n",
    "    \n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    y_true = df_combined['contem_dados_pessoais']\n",
    "    y_pred = df_combined['detectado_regex']\n",
    "    \n",
    "    print(\"Performance da Detecção por Regex (baseline):\\n\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['Sem dados', 'Com dados']))\n",
    "    \n",
    "    # Matriz de confusão\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Sem dados', 'Com dados'],\n",
    "                yticklabels=['Sem dados', 'Com dados'])\n",
    "    plt.title('Matriz de Confusão - Detecção por Regex', fontweight='bold')\n",
    "    plt.ylabel('Valor Real')\n",
    "    plt.xlabel('Valor Predito')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Análise de erros\n",
    "    print(\"\\nAnálise de Erros:\")\n",
    "    falsos_negativos = df_combined[(y_true == True) & (y_pred == False)]\n",
    "    print(f\"\\nFalsos Negativos (não detectados): {len(falsos_negativos)}\")\n",
    "    if len(falsos_negativos) > 0:\n",
    "        print(\"Exemplos:\")\n",
    "        for idx, row in falsos_negativos.head(3).iterrows():\n",
    "            print(f\"  - {row['texto_pedido'][:150]}...\")\n",
    "    \n",
    "    falsos_positivos = df_combined[(y_true == False) & (y_pred == True)]\n",
    "    print(f\"\\nFalsos Positivos (detectados incorretamente): {len(falsos_positivos)}\")\n",
    "    if len(falsos_positivos) > 0:\n",
    "        print(\"Exemplos:\")\n",
    "        for idx, row in falsos_positivos.head(3).iterrows():\n",
    "            print(f\"  - {row['texto_pedido'][:150]}...\")\n",
    "else:\n",
    "    print(\"Rótulos não disponíveis para análise de performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Próximos Passos\n",
    "\n",
    "Com base nesta análise exploratória, os próximos passos são:\n",
    "\n",
    "1. **Melhorar Detecção de Regex**:\n",
    "   - Ajustar padrões para reduzir falsos negativos\n",
    "   - Adicionar validação mais rigorosa para reduzir falsos positivos\n",
    "\n",
    "2. **Implementar NER**:\n",
    "   - Usar spaCy para detectar nomes próprios\n",
    "   - Filtrar falsos positivos (nomes de lugares, organizações)\n",
    "\n",
    "3. **Treinar Modelo ML**:\n",
    "   - TF-IDF + Random Forest/Logistic Regression\n",
    "   - Validação cruzada para avaliar generalização\n",
    "\n",
    "4. **Ensemble**:\n",
    "   - Combinar regex, NER e ML para maximizar F1-Score\n",
    "   - Ajustar thresholds para priorizar recall\n",
    "\n",
    "5. **Avaliação Final**:\n",
    "   - Testar no conjunto de controle da CGDF\n",
    "   - Otimizar para minimizar falsos negativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Salvar Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar dados com detecções\n",
    "caminho_saida = '../resultados/dados_com_deteccoes.csv'\n",
    "Path(caminho_saida).parent.mkdir(parents=True, exist_ok=True)\n",
    "df_combined.to_csv(caminho_saida, index=False)\n",
    "print(f\"Dados com detecções salvos em: {caminho_saida}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
